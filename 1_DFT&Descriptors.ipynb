{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "import warnings \n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from DFTStructureGenerator import DFThandle, xtb_process, mol_manipulation, logfile_process, Tool, gendes\n",
    "import glob, os\n",
    "from rdkit import Chem\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "from morfeus import BuriedVolume\n",
    "import pickle\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "OPT_METHOD = \"opt freq b3lyp/def2svpp em=gd3bj nosymm\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"Data\"\n",
    "row_csv = \"Data_clear.csv\"\n",
    "target_csv = \"Data_clear_with_sites.csv\"\n",
    "\n",
    "mol_xtb_file = os.path.join(data_dir, \"DFT\", 'Mol_xtb')\n",
    "mol_dir = os.path.join(data_dir, \"DFT\", 'Mols')\n",
    "dft_dir = os.path.join(data_dir, \"DFT\", 'GS_OPT')\n",
    "cu_mol_dir = os.path.join(data_dir, \"DFT\", 'newmols')\n",
    "cu_dft_dir = os.path.join(data_dir, \"DFT\", 'newGS')\n",
    "\n",
    "for file_ in [mol_xtb_file, mol_dir, dft_dir, cu_mol_dir, cu_dft_dir]:\n",
    "    if not os.path.exists(file_):\n",
    "        os.makedirs(file_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. DFT Optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Input Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smiles_csv = pd.read_csv(row_csv)\n",
    "for id, row in smiles_csv.iterrows():\n",
    "    smiles = row['Smiles']\n",
    "    smiles = Chem.MolToSmiles(Chem.MolFromSmiles(smiles))\n",
    "    row['Smiles'] = smiles\n",
    "    idx = row[\"Index\"]\n",
    "    if os.path.exists(f\"{mol_dir}/{idx:05}.mol\"):\n",
    "        continue\n",
    "    mol = mol_manipulation.smiles2mol(smiles)\n",
    "    Chem.AllChem.UFFOptimizeMolecule(mol)\n",
    "    Chem.MolToMolFile(mol, f\"{mol_dir}/{idx:05}.mol\")\n",
    "smiles_csv.to_csv(\"Data_clear.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DFThandle.Single_Xtb(data_dir, row_csv)\n",
    "xtb_process.shift_to_parra(mol_xtb_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DFThandle.smiles_DFT_calc(mol_xtb_file, mol_dir, dft_dir, method = OPT_METHOD, conf_limit = 10, SpinMultiplicity=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DFThandle.error_improve(data_dir, mol_dir, \"GS_OPT\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summarize Reaction Sites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smiles_csv = pd.read_csv(row_csv)\n",
    "smiles_csv['Sites'] = {}\n",
    "for row_id, row in smiles_csv.iterrows():\n",
    "    binol_smiles = row[\"Smiles\"]\n",
    "    binol_mol = Chem.MolFromSmiles(binol_smiles)\n",
    "    if row[\"Type\"] == \"Binol\":\n",
    "        subset = binol_mol.GetSubstructMatches(Chem.MolFromSmarts(\"[OH]c1ccccc1-c1ccccc1[OH]\"))\n",
    "        subset = subset[0]\n",
    "        smiles_csv['Sites'][row_id] = f\"{subset[0]} {subset[-1]}\"\n",
    "    elif row[\"Type\"] in [\"Ligand_Box\", \"Ligand_Other\"]:\n",
    "        mol = binol_mol\n",
    "        Chem.Kekulize(mol, clearAromaticFlags=True)\n",
    "        sites = set()\n",
    "        subset = mol.GetSubstructMatches(Chem.MolFromSmarts(\"N~*~*~N\"))\n",
    "        if len(subset) == 0:\n",
    "            subset = mol.GetSubstructMatches(Chem.MolFromSmarts(\"N~*~*~*~N\"))\n",
    "        if len(subset) == 0:\n",
    "            subset = mol.GetSubstructMatches(Chem.MolFromSmarts(\"N~*~*~*~O\"))\n",
    "        if len(subset) == 0:\n",
    "            subset = mol.GetSubstructMatches(Chem.MolFromSmarts(\"N~*~*~*~P\"))\n",
    "        if len(subset) == 0:\n",
    "            subset = mol.GetSubstructMatches(Chem.MolFromSmarts(\"N~*~*~*~*~N\"))\n",
    "        if len(subset) == 0:\n",
    "            subset = mol.GetSubstructMatches(Chem.MolFromSmarts(\"N~*~*~*~*~*~N\"))\n",
    "        for subset_ in subset:\n",
    "            sites.add(subset_[0])\n",
    "            sites.add(subset_[-1])\n",
    "        smiles_csv['Sites'][row_id] = \" \".join(str(site) for site in sites)\n",
    "smiles_csv.to_csv(target_csv, index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get DFT Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smiles_csv = pd.read_csv(target_csv)\n",
    "smiles_csv['conf_id'] = {}\n",
    "smiles_csv['G/Hatree'] = {}\n",
    "for row_id, row in smiles_csv.iterrows():\n",
    "    ligand_idx = row[\"Index\"]\n",
    "    mol = Chem.MolFromMolFile(os.path.join(mol_dir, f\"{ligand_idx:05}.mol\"), removeHs=False)\n",
    "    log_files = glob.glob(os.path.join(dft_dir, f\"{ligand_idx:05}*.log\"))\n",
    "    engs = []\n",
    "    conf_ids = []\n",
    "    for log_file in log_files:\n",
    "        conf_id = int(log_file.split(\"_\")[-1].split(\".\")[0])\n",
    "        log = logfile_process.Logfile(log_file)\n",
    "        eng = log.all_engs[0] + log.all_engs[-1]\n",
    "        engs.append(eng)\n",
    "        conf_ids.append(conf_id)\n",
    "    min_idx = np.argmin(engs)\n",
    "    min_conf_id = conf_ids[min_idx]\n",
    "    min_eng = engs[min_idx]\n",
    "    smiles_csv[\"conf_id\"][row_id] = min_conf_id\n",
    "    smiles_csv['G/Hatree'][row_id] = min_eng\n",
    "smiles_csv.to_csv(target_csv, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. DFT Optimization With Cu2+"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DFThandle.generate_ligand_cu_guesses(target_csv, mol_dir, dft_dir, cu_mol_dir, cu_dft_dir, M_L_DIST=1.96, OPT_METHOD=OPT_METHOD)\n",
    "DFThandle.generate_binol_cu_guesses(target_csv, mol_dir, dft_dir, cu_mol_dir, cu_dft_dir, M_L_DIST=1.96, OPT_METHOD=OPT_METHOD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DFThandle.error_improve(data_dir, cu_mol_dir, \"newGS\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Descriptor Calculation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normal DFT Descriptors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "627it [07:50,  1.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data\\newGS\\00785.log didn't run successful\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "845it [08:18,  1.70it/s]\n"
     ]
    }
   ],
   "source": [
    "smiles_csv = pd.read_csv(target_csv)\n",
    "qm_dict = {}\n",
    "for row_id, row in tqdm(smiles_csv.iterrows()):\n",
    "    des = []\n",
    "    ligand_idx = row[\"Index\"]\n",
    "    ligand_smiles = row[\"Smiles\"]\n",
    "    ligand_type = row[\"Type\"]\n",
    "    ligand_conf_id = row[\"conf_id\"]\n",
    "    ligand_G = row['G/Hatree']\n",
    "    sites = [int(each) for each in row['Sites'].split()]\n",
    "    mol = Chem.MolFromMolFile(os.path.join(mol_dir, f\"{ligand_idx:05}.mol\"), removeHs=False)\n",
    "    log = logfile_process.Logfile(os.path.join(dft_dir, f\"{ligand_idx:05}_r_{ligand_conf_id:04}.log\"))\n",
    "    newlog = logfile_process.Logfile(os.path.join(cu_dft_dir, f\"{ligand_idx:05}.log\"))\n",
    "    # new_G = newlog.all_engs[0] + newlog.all_engs[-1]\n",
    "    # des += [new_G - ligand_G +1639.93]\n",
    "    # log = newlog\n",
    "    positions = log.running_positions[-1]\n",
    "    symbol_lists = log.symbol_list\n",
    "    # 键长   \n",
    "    if ligand_type == \"Binol\":\n",
    "        subset = mol.GetSubstructMatches(Chem.MolFromSmarts(\"[OH]c1ccccc1-c1ccccc1[OH]\"))[0]\n",
    "        assert subset[0] == sites[0] and subset[-1] == sites[-1]\n",
    "        sites = np.array(subset)[[0,1,6,7,-2,-1]]\n",
    "        des += Tool.get_max_min_bond(positions, [[[sites[0], sites[1]], [sites[4], sites[5]]], [[sites[1], sites[2]], [sites[3], sites[4]]], [[sites[2], sites[3]], [sites[2], sites[3]]]])[:-1]\n",
    "        des += Tool.get_max_min_angle(positions, [[[sites[0], sites[1], sites[2]], [sites[3], sites[4], sites[5]]], [[sites[1], sites[2], sites[3]], [sites[2], sites[3], sites[4]]]])\n",
    "        des += [Tool.get_torsion_(positions[sites[1]], positions[sites[2]], positions[sites[3]], positions[sites[4]])]\n",
    "        new_subset = mol.GetSubstructMatches(Chem.MolFromSmarts(\"[OH]c1ccc2c(cccc2)c1c3c4c(cccc4)ccc3[OH]\"))\n",
    "        if len(new_subset) > 0:\n",
    "            new_subset = new_subset[0]\n",
    "            target_idx = [[new_subset[7], new_subset[16]], [new_subset[8], new_subset[15]], [new_subset[3], new_subset[18]], [new_subset[2], new_subset[19]]]\n",
    "        else:\n",
    "            new_subset = subset\n",
    "            target_idx = [[new_subset[5], new_subset[8]], [new_subset[4], new_subset[9]], [new_subset[3], new_subset[10]], [new_subset[2], new_subset[11]]]\n",
    "        neighbor_sites = [[[neighbor.GetIdx() for neighbor in mol.GetAtomWithIdx(site).GetNeighbors() if neighbor.GetIdx() not in new_subset][0] for site in target_idx_] for target_idx_ in target_idx]\n",
    "        BVs = [[BuriedVolume(symbol_lists, positions, each_neighbor + 1, include_hs=1, radius=4, z_axis_atoms=[each_target_idx + 1], excluded_atoms=[each_target_idx + 1]) for each_neighbor, each_target_idx in zip(neighbor_sites_, target_idx_)] for neighbor_sites_, target_idx_ in zip(neighbor_sites, target_idx)]\n",
    "        [[bv.octant_analysis() for bv in BVs_] for BVs_ in BVs]\n",
    "        BVs = [[bv.buried_volume / (bv.buried_volume + bv.free_volume) for bv in BVs_] for BVs_ in BVs]\n",
    "        des += np.array([[np.max(BVs_), np.min(BVs_)] for BVs_ in BVs]).flatten().tolist()\n",
    "        charges = np.array(log.read_charge_spin_density()[0])\n",
    "        des += list(charges[sites])\n",
    "    else:\n",
    "        charges = np.array(log.read_charge_spin_density()[0])\n",
    "        des += [np.max(charges[2]), np.min(charges[sites])]\n",
    "        if ligand_type == \"Ligand_Box\": des += [1]\n",
    "        else: des += [0]\n",
    "    des += log.read_orbit_eng()\n",
    "    des += [log.get_dipole()]\n",
    "    des += [len(sites)]\n",
    "    qm_dict[ligand_idx] = des"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grid Points Descriptors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "630it [00:35, 13.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data/newGS\\00785.log didn't run successful\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "845it [00:46, 18.36it/s]\n"
     ]
    }
   ],
   "source": [
    "cu_mol_dir = \"Data/newmols\"\n",
    "cu_dft_dir = \"Data/newGS\"\n",
    "smiles_csv = pd.read_csv(\"Data_clear_with_sites.csv\")\n",
    "# smiles_csv = smiles_csv.loc[(smiles_csv['Type'] == \"Binol\")]\n",
    "area_dict = {}\n",
    "for row_id, row in tqdm(smiles_csv.iterrows()):\n",
    "    ligand_idx = row[\"Index\"]\n",
    "    conf_id = row[\"conf_id\"]\n",
    "    ligand_type = row['Type']\n",
    "    sites = [int(each) for each in row['Sites'].split()]\n",
    "    mol = Chem.MolFromMolFile(os.path.join(cu_mol_dir, f\"{ligand_idx:05}.mol\"), removeHs=False)\n",
    "    log = logfile_process.Logfile(os.path.join(cu_dft_dir, f\"{ligand_idx:05}.log\"))\n",
    "    symbol_list, positions = log.symbol_list, log.running_positions[-1]\n",
    "    cu_atom_id = [atom.GetIdx() for atom in mol.GetAtoms() if atom.GetSymbol() == \"Cu\"][0]\n",
    "    out_position = mol_manipulation.trfm_rot(positions[sites[0]], positions[sites[-1]], positions[cu_atom_id], positions)\n",
    "    if out_position[cu_atom_id][1] < 0:\n",
    "        out_position = out_position @ mol_manipulation.rotation([1,0,0], 0, -1)\n",
    "    if ligand_type == \"Binol\":\n",
    "        subset = mol.GetSubstructMatches(Chem.MolFromSmarts(\"[OH]c1ccccc1-c1ccccc1[OH]\"))[0]\n",
    "        assert subset[0] == sites[0] and subset[-1] == sites[-1]\n",
    "        if out_position[subset[6]][2] < out_position[subset[7]][2]:\n",
    "            out_position[:, 2] *= -1\n",
    "    mol = xtb_process.xtb_to_mol(mol, [symbol_list], [out_position], 1)\n",
    "    sdf_file = os.path.join(cu_mol_dir, f\"{ligand_idx:05}.sdf\")\n",
    "    with Chem.SDWriter(sdf_file) as writer:\n",
    "        writer.write(mol)\n",
    "    areas = DFThandle.Calc_areas_(mol, sites + [cu_atom_id], radius=8, num_per_axis=20, count_per_axis = [4,4,4])\n",
    "    out_position = out_position @ mol_manipulation.rotation([1,0,0], 0, -1)\n",
    "    area_dict[ligand_idx] = areas\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f\"{data_dir}/all_fp_map.pkl\", 'wb')as f:\n",
    "    # pickle.dump([rd_mf_map, rd_des_map, morgan_map, modred_map, acsf_3D_map, soap_3D_map, mbtr_3D_map, lmbtr_3D_map, qm_dict, area_dict], f)\n",
    "    pickle.dump([qm_dict, area_dict], f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(r\"Data/all_fp_map.pkl\", 'rb')as f:\n",
    "    # rd_mf_map, rd_des_map, morgan_map, modred_map, acsf_3D_map, soap_3D_map, mbtr_3D_map, lmbtr_3D_map, qm_dict, area_dict = pickle.load(f)\n",
    "    qm_dict, area_dict = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Binol</th>\n",
       "      <th>Ligand</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7827</th>\n",
       "      <td>130</td>\n",
       "      <td>1201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7828</th>\n",
       "      <td>130</td>\n",
       "      <td>1202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7829</th>\n",
       "      <td>130</td>\n",
       "      <td>1203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7830</th>\n",
       "      <td>130</td>\n",
       "      <td>1204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7831</th>\n",
       "      <td>130</td>\n",
       "      <td>1205</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7832 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Binol  Ligand\n",
       "0         0    1001\n",
       "1         0    1003\n",
       "2         0    1004\n",
       "3         0    1005\n",
       "4         0    1006\n",
       "...     ...     ...\n",
       "7827    130    1201\n",
       "7828    130    1202\n",
       "7829    130    1203\n",
       "7830    130    1204\n",
       "7831    130    1205\n",
       "\n",
       "[7832 rows x 2 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "main_py3_12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
