{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6b814ced",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "import warnings \n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8c7932a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os, glob, shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "3739e0c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(178, 44)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_num_df = pd.read_excel('New_number.xlsx')\n",
    "translation_dict = {old: new for new, old in zip(new_num_df['New'], new_num_df['Old'])}\n",
    "old_space_df = pd.read_csv(r'ignored\\ConnectToHTE\\Data\\full_space.csv')\n",
    "old_space_binol = np.unique(old_space_df['Binol'].to_numpy())\n",
    "old_space_ligand = np.unique(old_space_df['Ligand'].to_numpy())\n",
    "len(old_space_ligand), len(old_space_binol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "ddda2c10",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert np.all(np.isin(old_space_binol, new_num_df['Old']))\n",
    "assert np.all(np.isin(old_space_ligand, new_num_df['Old']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cc7259d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_csv = pd.read_csv(\"ignored/backup/Data_clear.csv\")\n",
    "data_csv['Index'] = data_csv['Index'].map(translation_dict)\n",
    "data_csv.drop(columns=['Type_Index'], inplace=True)\n",
    "data_csv = data_csv.dropna().reset_index(drop=True)\n",
    "data_csv['Index'] = data_csv['Index'].astype(int)\n",
    "data_csv.sort_values(by=['Index'], inplace=True)\n",
    "# data_csv.to_csv('Data_clear.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1009478f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for row_id, row in new_num_df.iterrows():\n",
    "    new, old = row['New'], row[\"Old\"]\n",
    "    for subdir in ['GS_OPT', 'Mols', \"newGS\", 'newmols']:\n",
    "        files = glob.glob(f\"ignored/backup/{subdir}/{old:05}*\")\n",
    "        for each in files:\n",
    "            new_file = os.path.join(f'Data/DFT/{subdir}', os.path.basename(each).replace(f'{old:05}', f'{new:05}'))\n",
    "            # shutil.copy(each, new_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6becbcda",
   "metadata": {},
   "outputs": [],
   "source": [
    "for row_id, row in new_num_df.iterrows():\n",
    "    new, old = row['New'], row[\"Old\"]\n",
    "    paths = glob.glob(f\"ignored/backup/Mol_xtb/*/{old:05}*\")\n",
    "    for each in paths[:0]:\n",
    "        new_path = os.path.join(f'Data/DFT/Mol_xtb/charge_0_0', os.path.basename(each).replace(f'{old:05}', f'{new:05}'))\n",
    "        # shutil.copytree(each, new_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "e66e9fa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(r\"Data/all_fp_map2.pkl\", 'rb')as f:\n",
    "    qm_dict, area_dict = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "35116f21",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_qm_dict = {row['New']: qm_dict[row['Old']] for _, row in new_num_df.iterrows()}\n",
    "new_area_dict = {row['New']: area_dict[row['Old']] for _, row in new_num_df.iterrows()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a651fbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(r\"Data/all_fp_map.pkl\", 'wb')as f:\n",
    "#     pickle.dump([new_qm_dict, new_area_dict], f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "2c6afb97",
   "metadata": {},
   "outputs": [],
   "source": [
    "for csv in glob.glob(\"Data/*/*.csv\") + glob.glob(\"Data/*.csv\"):\n",
    "    df = pd.read_csv(csv)\n",
    "    # print(len(df))\n",
    "    for name in ['Binol_smiles', 'Ligand_smiles', 'Binol_conf_id', 'Ligand_conf_id', 'Binol_Sites', 'Ligand_Sites', 'Binol_G', 'Ligand_G', 'Unnamed: 4']:\n",
    "        if name in df.columns:\n",
    "            df = df.drop(columns = name)\n",
    "    # df[\"Binol\"] = df[\"Binol\"].map(translation_dict)\n",
    "    # df[\"Ligand\"] = df[\"Ligand\"].map(translation_dict)\n",
    "    # df = df.dropna().reset_index(drop=True)\n",
    "    df['Binol'] = df['Binol'].astype(int)\n",
    "    df['Ligand'] = df['Ligand'].astype(int)\n",
    "    df.to_csv(csv, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11a70bfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "for csv in glob.glob(\"Data/Iteration_2/Result/*.csv\"):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "7f37059c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for id_ in range(1,16):\n",
    "    csv = f\"Data/Iteration_2/Result_/BINOL_result_{id_:04}.csv\"\n",
    "    new_csv = f\"Data/Iteration_2/Result_/BINOL_result_{id_ - 1:04}.csv\"\n",
    "    shutil.move(csv, new_csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "e9a092f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "for id_ in range(15):\n",
    "    csv = f\"Data/Iteration_2/Result/BINOL_result_{id_:04}.csv\"\n",
    "    newcsv = f\"Data/Iteration_2/Iteration_Data/iter_{id_:05}.csv\"\n",
    "    df = pd.read_csv(csv)\n",
    "    df.drop(columns=['R', 'S'], inplace=True, errors='ignore')\n",
    "    df.to_csv(newcsv, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "2c6fcdc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "AL_data = pd.read_csv(\"Data/Iteration_2/Full_Space_ActiveLearning.csv\")\n",
    "AL_id = [f'{row.Binol:05}_{row.Ligand:05}' for _, row in AL_data.iterrows()]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "64aaacd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50\n",
      "50\n",
      "50\n",
      "50\n",
      "50\n",
      "50\n",
      "50\n",
      "50\n",
      "50\n",
      "50\n",
      "50\n",
      "50\n",
      "50\n",
      "50\n",
      "50\n"
     ]
    }
   ],
   "source": [
    "for id_ in range(15):\n",
    "    csv = f\"Data/Iteration_2/Iteration_Data/iter_{id_:05}.csv\"\n",
    "    df = pd.read_csv(csv)\n",
    "    temp_id = [f'{int(row.Binol):05}_{int(row.Ligand):05}' for _, row in df.iterrows()]\n",
    "    collect_id = [AL_id.index(t_id) for t_id in temp_id]\n",
    "    print(len(collect_id))\n",
    "    np.save(f\"Data/Iteration_2/Iteration_Data/iter_{id_:05}.npy\", np.array(collect_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db31a3ae",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "main_py3_12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
