{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6b814ced",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "import warnings \n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8c7932a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os, glob, shutil\n",
    "from DFTStructureGenerator import logfile_process, FormatConverter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3739e0c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(178, 44)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_num_df = pd.read_excel('New_number_BINOL.xlsx')\n",
    "translation_dict = {old: new for new, old in zip(new_num_df['New_number'], new_num_df['Old_number'])}\n",
    "old_space_df = pd.read_csv(r'Data\\Iteration_2\\Full_Space_ActiveLearning.csv')\n",
    "old_space_binol = np.unique(old_space_df['Binol'].to_numpy())\n",
    "old_space_ligand = np.unique(old_space_df['Ligand'].to_numpy())\n",
    "len(old_space_ligand), len(old_space_binol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ddda2c10",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert np.all(np.isin(old_space_binol, new_num_df['Old_number']))\n",
    "assert np.all(np.isin(old_space_ligand, new_num_df['Old_number']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4cc7259d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_csv = pd.read_csv(\"Data_clear_with_sites.csv\")\n",
    "data_csv['Index'] = data_csv['Index'].map(translation_dict)\n",
    "data_csv.drop(columns=['Type_Index'], inplace=True)\n",
    "data_csv = data_csv.dropna().reset_index(drop=True)\n",
    "data_csv['Index'] = data_csv['Index'].astype(int)\n",
    "data_csv.sort_values(by=['Index'], inplace=True)\n",
    "data_csv.to_csv('Data_clear_with_sites.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "22b57cee",
   "metadata": {},
   "outputs": [
    {
     "ename": "PermissionError",
     "evalue": "[Errno 13] Permission denied: 'BINOL_result_Fig4_L1009.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mPermissionError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 5\u001b[0m\n\u001b[0;32m      3\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mBinol\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mBinol\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mmap(translation_dict)\n\u001b[0;32m      4\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLigand\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLigand\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mmap(translation_dict)\n\u001b[1;32m----> 5\u001b[0m \u001b[43mdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcsv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Jackie\\anaconda3\\envs\\main_py3_12\\Lib\\site-packages\\pandas\\util\\_decorators.py:333\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    327\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[0;32m    328\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    329\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39m_format_argument_list(allow_args)),\n\u001b[0;32m    330\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[0;32m    331\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(),\n\u001b[0;32m    332\u001b[0m     )\n\u001b[1;32m--> 333\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Jackie\\anaconda3\\envs\\main_py3_12\\Lib\\site-packages\\pandas\\core\\generic.py:3967\u001b[0m, in \u001b[0;36mNDFrame.to_csv\u001b[1;34m(self, path_or_buf, sep, na_rep, float_format, columns, header, index, index_label, mode, encoding, compression, quoting, quotechar, lineterminator, chunksize, date_format, doublequote, escapechar, decimal, errors, storage_options)\u001b[0m\n\u001b[0;32m   3956\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m, ABCDataFrame) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mto_frame()\n\u001b[0;32m   3958\u001b[0m formatter \u001b[38;5;241m=\u001b[39m DataFrameFormatter(\n\u001b[0;32m   3959\u001b[0m     frame\u001b[38;5;241m=\u001b[39mdf,\n\u001b[0;32m   3960\u001b[0m     header\u001b[38;5;241m=\u001b[39mheader,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   3964\u001b[0m     decimal\u001b[38;5;241m=\u001b[39mdecimal,\n\u001b[0;32m   3965\u001b[0m )\n\u001b[1;32m-> 3967\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mDataFrameRenderer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mformatter\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_csv\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   3968\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpath_or_buf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3969\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlineterminator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlineterminator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3970\u001b[0m \u001b[43m    \u001b[49m\u001b[43msep\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msep\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3971\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3972\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3973\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcompression\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3974\u001b[0m \u001b[43m    \u001b[49m\u001b[43mquoting\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquoting\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3975\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3976\u001b[0m \u001b[43m    \u001b[49m\u001b[43mindex_label\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex_label\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3977\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3978\u001b[0m \u001b[43m    \u001b[49m\u001b[43mchunksize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunksize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3979\u001b[0m \u001b[43m    \u001b[49m\u001b[43mquotechar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquotechar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3980\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdate_format\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdate_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3981\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdoublequote\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdoublequote\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3982\u001b[0m \u001b[43m    \u001b[49m\u001b[43mescapechar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mescapechar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3983\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3984\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Jackie\\anaconda3\\envs\\main_py3_12\\Lib\\site-packages\\pandas\\io\\formats\\format.py:1014\u001b[0m, in \u001b[0;36mDataFrameRenderer.to_csv\u001b[1;34m(self, path_or_buf, encoding, sep, columns, index_label, mode, compression, quoting, quotechar, lineterminator, chunksize, date_format, doublequote, escapechar, errors, storage_options)\u001b[0m\n\u001b[0;32m    993\u001b[0m     created_buffer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    995\u001b[0m csv_formatter \u001b[38;5;241m=\u001b[39m CSVFormatter(\n\u001b[0;32m    996\u001b[0m     path_or_buf\u001b[38;5;241m=\u001b[39mpath_or_buf,\n\u001b[0;32m    997\u001b[0m     lineterminator\u001b[38;5;241m=\u001b[39mlineterminator,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1012\u001b[0m     formatter\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfmt,\n\u001b[0;32m   1013\u001b[0m )\n\u001b[1;32m-> 1014\u001b[0m \u001b[43mcsv_formatter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1016\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m created_buffer:\n\u001b[0;32m   1017\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(path_or_buf, StringIO)\n",
      "File \u001b[1;32mc:\\Users\\Jackie\\anaconda3\\envs\\main_py3_12\\Lib\\site-packages\\pandas\\io\\formats\\csvs.py:251\u001b[0m, in \u001b[0;36mCSVFormatter.save\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    247\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    248\u001b[0m \u001b[38;5;124;03mCreate the writer & save.\u001b[39;00m\n\u001b[0;32m    249\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    250\u001b[0m \u001b[38;5;66;03m# apply compression and byte/text conversion\u001b[39;00m\n\u001b[1;32m--> 251\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    252\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    253\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    254\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    256\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompression\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    257\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    258\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m handles:\n\u001b[0;32m    259\u001b[0m     \u001b[38;5;66;03m# Note: self.encoding is irrelevant here\u001b[39;00m\n\u001b[0;32m    260\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwriter \u001b[38;5;241m=\u001b[39m csvlib\u001b[38;5;241m.\u001b[39mwriter(\n\u001b[0;32m    261\u001b[0m         handles\u001b[38;5;241m.\u001b[39mhandle,\n\u001b[0;32m    262\u001b[0m         lineterminator\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlineterminator,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    267\u001b[0m         quotechar\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mquotechar,\n\u001b[0;32m    268\u001b[0m     )\n\u001b[0;32m    270\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_save()\n",
      "File \u001b[1;32mc:\\Users\\Jackie\\anaconda3\\envs\\main_py3_12\\Lib\\site-packages\\pandas\\io\\common.py:873\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    868\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m    869\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[0;32m    870\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[0;32m    871\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[0;32m    872\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[1;32m--> 873\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[0;32m    874\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    875\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    876\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    877\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    878\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    879\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    880\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    881\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[0;32m    882\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[1;31mPermissionError\u001b[0m: [Errno 13] Permission denied: 'BINOL_result_Fig4_L1009.csv'"
     ]
    }
   ],
   "source": [
    "csv = 'BINOL_result_Fig4_L1009.csv'\n",
    "df = pd.read_csv(csv)\n",
    "df['Binol'] = df['Binol'].map(translation_dict)\n",
    "df['Ligand'] = df['Ligand'].map(translation_dict)\n",
    "df.to_csv(csv, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1009478f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for row_id, row in new_num_df.iterrows():\n",
    "    new, old = row['New_number'], row[\"Old_number\"]\n",
    "    for subdir in ['GS_OPT', 'Mols', \"newGS\", 'newmols']:\n",
    "        if not os.path.isdir(f'Data/DFT/{subdir}'):\n",
    "            os.mkdir(f'Data/DFT/{subdir}')\n",
    "        files = glob.glob(f\"ignored/backup/{subdir}/{old:05}*\")\n",
    "        for each in files:\n",
    "            new_file = os.path.join(f'Data/DFT/{subdir}', os.path.basename(each).replace(f'{old:05}', f'{new:05}'))\n",
    "            shutil.copy(each, new_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6becbcda",
   "metadata": {},
   "outputs": [],
   "source": [
    "for row_id, row in new_num_df.iterrows():\n",
    "    new, old = row['New'], row[\"Old\"]\n",
    "    paths = glob.glob(f\"ignored/backup/Mol_xtb/*/{old:05}*\")\n",
    "    for each in paths[:0]:\n",
    "        new_path = os.path.join(f'Data/DFT/Mol_xtb/charge_0_0', os.path.basename(each).replace(f'{old:05}', f'{new:05}'))\n",
    "        # shutil.copytree(each, new_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e66e9fa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(r\"Data/all_fp_map.pkl\", 'rb')as f:\n",
    "    qm_dict, area_dict = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "35116f21",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "0",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[20], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m new_qm_dict \u001b[38;5;241m=\u001b[39m {row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNew_number\u001b[39m\u001b[38;5;124m'\u001b[39m]: \u001b[43mqm_dict\u001b[49m\u001b[43m[\u001b[49m\u001b[43mrow\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mOld_number\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m _, row \u001b[38;5;129;01min\u001b[39;00m new_num_df\u001b[38;5;241m.\u001b[39miterrows()}\n\u001b[0;32m      2\u001b[0m new_area_dict \u001b[38;5;241m=\u001b[39m {row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNew_number\u001b[39m\u001b[38;5;124m'\u001b[39m]: area_dict[row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mOld_number\u001b[39m\u001b[38;5;124m'\u001b[39m]] \u001b[38;5;28;01mfor\u001b[39;00m _, row \u001b[38;5;129;01min\u001b[39;00m new_num_df\u001b[38;5;241m.\u001b[39miterrows()}\n",
      "\u001b[1;31mKeyError\u001b[0m: 0"
     ]
    }
   ],
   "source": [
    "new_qm_dict = {row['New_number']: qm_dict[row['Old_number']] for _, row in new_num_df.iterrows()}\n",
    "new_area_dict = {row['New_number']: area_dict[row['Old_number']] for _, row in new_num_df.iterrows()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a651fbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(r\"Data/all_fp_map.pkl\", 'wb')as f:\n",
    "#     pickle.dump([new_qm_dict, new_area_dict], f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "2c6afb97",
   "metadata": {},
   "outputs": [],
   "source": [
    "for csv in glob.glob(\"Data/Iteration_2/Result/*.csv\"):\n",
    "    df = pd.read_csv(csv)\n",
    "    # print(len(df))\n",
    "    for name in ['Binol_smiles', 'Ligand_smiles', 'Binol_conf_id', 'Ligand_conf_id', 'Binol_Sites', 'Ligand_Sites', 'Binol_G', 'Ligand_G', 'Unnamed: 4']:\n",
    "        if name in df.columns:\n",
    "            df = df.drop(columns = name)\n",
    "    df[\"Binol\"] = df[\"Binol\"].map(translation_dict)\n",
    "    df[\"Ligand\"] = df[\"Ligand\"].map(translation_dict)\n",
    "    # df = df.dropna().reset_index(drop=True)\n",
    "    df['Binol'] = df['Binol'].astype(int)\n",
    "    df['Ligand'] = df['Ligand'].astype(int)\n",
    "\n",
    "    df.to_csv(csv.replace('Result', \"Result_\"), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "7f37059c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for id_ in range(1,16):\n",
    "    csv = f\"Data/Iteration_2/Result/BINOL_result_{id_:04}.csv\"\n",
    "    new_csv = f\"Data/Iteration_2/Result/BINOL_result_{id_ - 1:04}.csv\"\n",
    "    shutil.move(csv, new_csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "e9a092f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "for id_ in range(15):\n",
    "    csv = f\"Data/Iteration_2/Result/BINOL_result_{id_:04}.csv\"\n",
    "    newcsv = f\"Data/Iteration_2/Iteration_Data/iter_{id_:05}.csv\"\n",
    "    df = pd.read_csv(csv)\n",
    "    df.drop(columns=['R', 'S'], inplace=True, errors='ignore')\n",
    "    df.to_csv(newcsv, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "2c6fcdc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "AL_data = pd.read_csv(\"Data/Iteration_2/Full_Space_ActiveLearning.csv\")\n",
    "AL_id = [f'{row.Binol:05}_{row.Ligand:05}' for _, row in AL_data.iterrows()]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "64aaacd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50\n",
      "50\n",
      "50\n",
      "50\n",
      "50\n",
      "50\n",
      "50\n",
      "50\n",
      "50\n",
      "50\n",
      "50\n",
      "50\n",
      "50\n",
      "50\n",
      "50\n"
     ]
    }
   ],
   "source": [
    "for id_ in range(15):\n",
    "    csv = f\"Data/Iteration_2/Iteration_Data/iter_{id_:05}.csv\"\n",
    "    df = pd.read_csv(csv)\n",
    "    temp_id = [f'{int(row.Binol):05}_{int(row.Ligand):05}' for _, row in df.iterrows()]\n",
    "    collect_id = [AL_id.index(t_id) for t_id in temp_id]\n",
    "    print(len(collect_id))\n",
    "    np.save(f\"Data/Iteration_2/Iteration_Data/iter_{id_:05}.npy\", np.array(collect_id))\n",
    "    # break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09aab6b7",
   "metadata": {},
   "source": [
    "# CuBox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "id": "a4c559df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Can't find title\n",
      "Can't find title\n"
     ]
    }
   ],
   "source": [
    "methods = [\n",
    "    '#p b3lyp nosymm def2tzvpp em=gd3bj scrf=(smd,solvent=dichloromethane)',\n",
    "    '#p M06 nosymm def2tzvpp scrf=(smd,solvent=dichloromethane)', \n",
    "    '#p m062x nosymm def2tzvpp scrf=(smd,solvent=dichloromethane)', \n",
    "    '#p wb97xd nosymm def2tzvpp scrf=(smd,solvent=dichloromethane)', \n",
    "    '#p pbe1pbe nosymm def2tzvpp em=gd3bj scrf=(smd,solvent=dichloromethane)'\n",
    "]\n",
    "names = ['b3lyp', 'M06', 'm062x', 'wb97xd', 'pbe0']\n",
    "target_dir = 'ignored/DFT/b3def2svp'\n",
    "for x in ['R', \"S\"]:\n",
    "    log = logfile_process.Logfile(os.path.join(target_dir, f'{x}.log'))\n",
    "    for name, method in zip(names, methods):\n",
    "        FormatConverter.block_to_gjf(log.symbol_list, log.running_positions[-1], os.path.join(target_dir, f'{x}_{name}.gjf'), method=method, charge=log.charge, multiplicity=log.multiplicity)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "id": "9d8e96bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Can't find title\n",
      "Can't find title\n",
      "Can't find title\n",
      "Can't find title\n",
      "Can't find title\n",
      "Can't find title\n",
      "Can't find title\n",
      "Can't find title\n",
      "Can't find title\n",
      "Can't find title\n",
      "ignored/DFT\\b3def2svp\\R_M062x.log didn't run successful\n",
      "ignored/DFT\\b3def2svp\\R_M062x.log 应该是没跑完\n",
      "ignored/DFT\\b3def2svp\\R_M062x.log, can't find any engs\n",
      "Can't find title\n",
      "Can't find title\n",
      "Can't find title\n",
      "Can't find title\n",
      "Can't find title\n",
      "Can't find title\n",
      "ignored/DFT\\b3def2svp(solvent)\\R_m062x.log didn't run successful\n",
      "Can't find title\n",
      "Can't find title\n",
      "Can't find title\n",
      "Can't find title\n",
      "Can't find title\n",
      "ignored/DFT\\m062x_def2svp(solvent)\\S.log didn't run successful\n",
      "Can't find title\n"
     ]
    }
   ],
   "source": [
    "all_opt_dirs = glob.glob(\"ignored/DFT/*\")\n",
    "result_df = pd.DataFrame(columns=['OPT_method', 'SPE_method', 'R_G', 'S_G', 'deltaG'])\n",
    "for each_dir in all_opt_dirs:\n",
    "    if not os.path.isdir(each_dir):\n",
    "        continue\n",
    "    R_log_file = os.path.join(each_dir, \"R.log\")\n",
    "    S_log_file = os.path.join(each_dir, \"S.log\")\n",
    "    if not (os.path.isfile(R_log_file) and os.path.isfile(S_log_file)):\n",
    "        continue\n",
    "    R_log = logfile_process.Logfile(R_log_file)\n",
    "    S_log = logfile_process.Logfile(S_log_file)\n",
    "    if not R_log.normal_end or not S_log.normal_end:\n",
    "        continue\n",
    "    R_G_cor = R_log.all_engs[-1]\n",
    "    S_G_cor = S_log.all_engs[-1]\n",
    "\n",
    "    result_df = result_df._append({\n",
    "        \"OPT_method\": each_dir.split(\"\\\\\")[-1],\n",
    "        \"SPE_method\": \"\\\\\",\n",
    "        \"R_G\": R_G_cor + R_log.all_engs[0],\n",
    "        \"S_G\": S_G_cor + S_log.all_engs[0],\n",
    "        \"deltaG\": (R_G_cor + R_log.all_engs[0] - S_G_cor - S_log.all_engs[0]) * 627.5\n",
    "    }, ignore_index=True)\n",
    "\n",
    "    R_spe_logs = glob.glob(os.path.join(each_dir, \"R_*.log\"))\n",
    "    for R_spe_log in R_spe_logs:\n",
    "        spe_name = os.path.basename(R_spe_log).split(\"_\")[1].split(\".\")[0]\n",
    "        S_spe_log = R_spe_log.replace(\"R_\", \"S_\")\n",
    "        if not os.path.isfile(S_spe_log):\n",
    "            continue\n",
    "        R_spe_log = logfile_process.Logfile(R_spe_log)\n",
    "        S_spe_log = logfile_process.Logfile(S_spe_log)\n",
    "        if not R_spe_log.normal_end or not S_spe_log.normal_end:\n",
    "            continue\n",
    "        R_spe_eng = R_spe_log.all_engs[-1]\n",
    "        S_spe_eng = S_spe_log.all_engs[-1]\n",
    "        R_G = R_spe_eng + R_G_cor\n",
    "        S_G = S_spe_eng + S_G_cor\n",
    "        deltaG = R_G - S_G\n",
    "        result_df = result_df._append({\n",
    "            \"OPT_method\": each_dir.split(\"\\\\\")[-1],\n",
    "            \"SPE_method\": spe_name,\n",
    "            \"R_G\": R_G,\n",
    "            \"S_G\": S_G,\n",
    "            \"deltaG\": deltaG * 627.5\n",
    "            \n",
    "        }, ignore_index=True)\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "id": "ab373f0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>OPT_method</th>\n",
       "      <th>SPE_method</th>\n",
       "      <th>R_G</th>\n",
       "      <th>S_G</th>\n",
       "      <th>deltaG</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1_4kcal</td>\n",
       "      <td>\\</td>\n",
       "      <td>-3707.420586</td>\n",
       "      <td>-3707.422692</td>\n",
       "      <td>1.321327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1_4kcal</td>\n",
       "      <td>sp</td>\n",
       "      <td>-3709.967456</td>\n",
       "      <td>-3709.969649</td>\n",
       "      <td>1.375894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2_0kcal</td>\n",
       "      <td>\\</td>\n",
       "      <td>-3707.419553</td>\n",
       "      <td>-3707.422692</td>\n",
       "      <td>1.969597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2_0kcal</td>\n",
       "      <td>m06l</td>\n",
       "      <td>-3709.966430</td>\n",
       "      <td>-3709.969649</td>\n",
       "      <td>2.019904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>b3def2svp</td>\n",
       "      <td>\\</td>\n",
       "      <td>-3707.949200</td>\n",
       "      <td>-3707.960094</td>\n",
       "      <td>6.836067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>b3def2svp</td>\n",
       "      <td>b3lyp</td>\n",
       "      <td>-3710.571368</td>\n",
       "      <td>-3710.577880</td>\n",
       "      <td>4.086399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>b3def2svp</td>\n",
       "      <td>M06</td>\n",
       "      <td>-3708.755541</td>\n",
       "      <td>-3708.760456</td>\n",
       "      <td>3.083949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>b3def2svp</td>\n",
       "      <td>pbe0</td>\n",
       "      <td>-3707.773672</td>\n",
       "      <td>-3707.780540</td>\n",
       "      <td>4.309701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>b3def2svp</td>\n",
       "      <td>wb97xd</td>\n",
       "      <td>-3709.661171</td>\n",
       "      <td>-3709.667288</td>\n",
       "      <td>3.838850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>b3def2svp(solvent)</td>\n",
       "      <td>\\</td>\n",
       "      <td>-3708.007841</td>\n",
       "      <td>-3708.017694</td>\n",
       "      <td>6.182808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>b3def2svp(solvent)</td>\n",
       "      <td>b3lyp</td>\n",
       "      <td>-3710.559722</td>\n",
       "      <td>-3710.568209</td>\n",
       "      <td>5.325191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>b3def2svp(solvent)</td>\n",
       "      <td>m06</td>\n",
       "      <td>-3708.744767</td>\n",
       "      <td>-3708.751310</td>\n",
       "      <td>4.105663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>b3def2svp(solvent)</td>\n",
       "      <td>wb97xd</td>\n",
       "      <td>-3709.649210</td>\n",
       "      <td>-3709.657185</td>\n",
       "      <td>5.004407</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            OPT_method SPE_method          R_G          S_G    deltaG\n",
       "0              1_4kcal          \\ -3707.420586 -3707.422692  1.321327\n",
       "1              1_4kcal         sp -3709.967456 -3709.969649  1.375894\n",
       "2              2_0kcal          \\ -3707.419553 -3707.422692  1.969597\n",
       "3              2_0kcal       m06l -3709.966430 -3709.969649  2.019904\n",
       "4            b3def2svp          \\ -3707.949200 -3707.960094  6.836067\n",
       "5            b3def2svp      b3lyp -3710.571368 -3710.577880  4.086399\n",
       "6            b3def2svp        M06 -3708.755541 -3708.760456  3.083949\n",
       "7            b3def2svp       pbe0 -3707.773672 -3707.780540  4.309701\n",
       "8            b3def2svp     wb97xd -3709.661171 -3709.667288  3.838850\n",
       "9   b3def2svp(solvent)          \\ -3708.007841 -3708.017694  6.182808\n",
       "10  b3def2svp(solvent)      b3lyp -3710.559722 -3710.568209  5.325191\n",
       "11  b3def2svp(solvent)        m06 -3708.744767 -3708.751310  4.105663\n",
       "12  b3def2svp(solvent)     wb97xd -3709.649210 -3709.657185  5.004407"
      ]
     },
     "execution_count": 246,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "id": "e7fbe4d7",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "140",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[247], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m translation_dict \u001b[38;5;241m=\u001b[39m {old: new \u001b[38;5;28;01mfor\u001b[39;00m new, old \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(new_num_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNew\u001b[39m\u001b[38;5;124m'\u001b[39m], new_num_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mOld\u001b[39m\u001b[38;5;124m'\u001b[39m])}\n\u001b[0;32m      3\u001b[0m new_2_num_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_excel(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNew_number_BINOL.xlsx\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m----> 4\u001b[0m new_2_translation_dict \u001b[38;5;241m=\u001b[39m {\u001b[43mtranslation_dict\u001b[49m\u001b[43m[\u001b[49m\u001b[43mold\u001b[49m\u001b[43m]\u001b[49m: new \u001b[38;5;28;01mfor\u001b[39;00m new, old \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(new_2_num_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNew_number\u001b[39m\u001b[38;5;124m'\u001b[39m], new_2_num_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mOld_number\u001b[39m\u001b[38;5;124m'\u001b[39m])}\n",
      "\u001b[1;31mKeyError\u001b[0m: 140"
     ]
    }
   ],
   "source": [
    "new_num_df = pd.read_excel('New_number.xlsx')\n",
    "translation_dict = {old: new for new, old in zip(new_num_df['New'], new_num_df['Old'])}\n",
    "new_2_num_df = pd.read_excel('New_number_BINOL.xlsx')\n",
    "new_2_translation_dict = {translation_dict[old]: new for new, old in zip(new_2_num_df['New_number'], new_2_num_df['Old_number'])}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "id": "b12f234e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys([1001, 1012, 1015, 1153, 1184, 1038, 1171, 1051, 1069, 1077, 1173, 1063, 1156, 1203, 1158, 1161, 1166, 1167, 1192, 1194, 1092, 1003, 1037, 1182, 1017, 1040, 1195, 1028, 1029, 1183, 1066, 1190, 1041, 1075, 1068, 1064, 1070, 1080, 1165, 1085, 1094, 1095, 1096, 1098, 1050, 1036, 1033, 1016, 1151, 1039, 1022, 1025, 1024, 1059, 1065, 1188, 1044, 1177, 1205, 1005, 1048, 1162, 1097, 1083, 1078, 1168, 1009, 1174, 1031, 1154, 1019, 1010, 1176, 1197, 1200, 1034, 1155, 1175, 1071, 1187, 1204, 1202, 1046, 1052, 1191, 1193, 1169, 1170, 1159, 1004, 1178, 1014, 1152, 1179, 1196, 1030, 1199, 1172, 1062, 1072, 1076, 1073, 1157, 1067, 1054, 1045, 1084, 1086, 1164, 1079, 1100, 1006, 1011, 1032, 1020, 1027, 1026, 1023, 1180, 1181, 1189, 1074, 1049, 1099, 1163, 1081, 1082, 1185, 1201, 1198, 1035, 1186, 1061, 1056, 1057, 1091, 1093, 1087, 1058, 1101, 1102, 1104, 1105, 1106, 1107, 1108, 1109, 1110, 1111, 1113, 1114, 1117, 1118, 1122, 1125, 1127, 1128, 1129, 1130, 1131, 1132, 1133, 1134, 1136, 1137, 1138, 1139, 1140, 1141, 1142, 1143, 1144, 1145, 1146, 1147, 1148, 1149, 1150, 0, 1, 2, 3, 13, 18, 62, 63, 66, 31, 32, 35, 36, 44, 45, 46, 47, 51, 52, 56, 57, 60, 85, 121, 91, 19, 20, 123, 124, 122, 24, 30, 126, 29, 23, 129, 127, 130, 21, 28, 26, 25, 128, 125, 781, 803, 795, 108, 179, 98, 210, 167, 145, 134, 133, 166, 138, 147, 149, 151, 141, 139, 273, 269, 802])"
      ]
     },
     "execution_count": 249,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "translation_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "id": "66db4bcb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys([1001, 1012, 1015, 1153, 1184, 1038, 1171, 1051, 1069, 1077, 1173, 1063, 1156, 1203, 1158, 1161, 1166, 1167, 1192, 1194, 1092, 1003, 1037, 1182, 1017, 1040, 1195, 1028, 1029, 1183, 1066, 1190, 1041, 1075, 1068, 1064, 1070, 1080, 1165, 1085, 1094, 1095, 1096, 1098, 1050, 1036, 1033, 1016, 1151, 1039, 1022, 1025, 1024, 1059, 1065, 1188, 1044, 1177, 1205, 1005, 1048, 1162, 1097, 1083, 1078, 1168, 1009, 1174, 1031, 1154, 1019, 1010, 1176, 1197, 1200, 1034, 1155, 1175, 1071, 1187, 1204, 1202, 1046, 1052, 1191, 1193, 1169, 1170, 1159, 1004, 1178, 1014, 1152, 1179, 1196, 1030, 1199, 1172, 1062, 1072, 1076, 1073, 1157, 1067, 1054, 1045, 1084, 1086, 1164, 1079, 1100, 1006, 1011, 1032, 1020, 1027, 1026, 1023, 1180, 1181, 1189, 1074, 1049, 1099, 1163, 1081, 1082, 1185, 1201, 1198, 1035, 1186, 1061, 1056, 1057, 1091, 1093, 1087, 1058, 1101, 1102, 1104, 1105, 1106, 1107, 1108, 1109, 1110, 1111, 1113, 1114, 1117, 1118, 1122, 1125, 1127, 1128, 1129, 1130, 1131, 1132, 1133, 1134, 1136, 1137, 1138, 1139, 1140, 1141, 1142, 1143, 1144, 1145, 1146, 1147, 1148, 1149, 1150, 0, 1, 2, 3, 13, 18, 62, 63, 66, 31, 32, 35, 36, 44, 45, 46, 47, 51, 52, 56, 57, 60, 85, 121, 91, 19, 20, 123, 124, 122, 24, 30, 126, 29, 23, 129, 127, 130, 21, 28, 26, 25, 128, 125, 781, 803, 795, 108, 179, 98, 210, 167, 145, 134, 133, 166, 138, 147, 149, 151, 141, 139, 273, 269, 802])"
      ]
     },
     "execution_count": 250,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "translation_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4a9b76fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 把63的分子提取出来\n",
    "target_files = glob.glob(f\"Data/DFT/*/*{63:05}*\")\n",
    "new_dir = glob.glob(\"ignored/backup2/*\")\n",
    "for file_ in target_files:\n",
    "    new_file = file_.replace(\"Data/DFT\", \"ignored/backup2\").replace(f'{63:05}', f'{273:05}')\n",
    "    if not os.path.isdir(os.path.dirname(new_file)):\n",
    "        os.mkdir(os.path.dirname(new_file))\n",
    "    shutil.copyfile(file_, new_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "id": "750a305d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'BINOL_result_Fig4_L1009.csv'"
      ]
     },
     "execution_count": 257,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2762fd7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "main_py3_12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
